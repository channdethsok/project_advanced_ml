{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71867248-5ef3-4ffc-93b1-74419739742a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>midi_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In sleep he sang to me\\nin dreams he came\\ntha...</td>\n",
       "      <td>data/lmd-full_and_reddit_MIDI_dataset/sentence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have plans and schemes\\nAnd I have hopes and...</td>\n",
       "      <td>data/lmd-full_and_reddit_MIDI_dataset/sentence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I get up and nothing gets me You got\\nit tough...</td>\n",
       "      <td>data/lmd-full_and_reddit_MIDI_dataset/sentence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man a hot like seven inches\\nfrom the midday I...</td>\n",
       "      <td>data/lmd-full_and_reddit_MIDI_dataset/sentence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We come from the land of the ice and snow\\nfro...</td>\n",
       "      <td>data/lmd-full_and_reddit_MIDI_dataset/sentence...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics  \\\n",
       "0  In sleep he sang to me\\nin dreams he came\\ntha...   \n",
       "1  I have plans and schemes\\nAnd I have hopes and...   \n",
       "2  I get up and nothing gets me You got\\nit tough...   \n",
       "3  Man a hot like seven inches\\nfrom the midday I...   \n",
       "4  We come from the land of the ice and snow\\nfro...   \n",
       "\n",
       "                                           midi_path  \n",
       "0  data/lmd-full_and_reddit_MIDI_dataset/sentence...  \n",
       "1  data/lmd-full_and_reddit_MIDI_dataset/sentence...  \n",
       "2  data/lmd-full_and_reddit_MIDI_dataset/sentence...  \n",
       "3  data/lmd-full_and_reddit_MIDI_dataset/sentence...  \n",
       "4  data/lmd-full_and_reddit_MIDI_dataset/sentence...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def extract_lyrics(npy_file):\n",
    "    \"\"\"\n",
    "    Extracts lyrics from a .npy file.\n",
    "\n",
    "    Args:\n",
    "        npy_file: Path to the input .npy file.\n",
    "\n",
    "    Returns:\n",
    "        A string containing the extracted lyrics.\n",
    "    \"\"\"\n",
    "    data = np.load(npy_file, allow_pickle=True)\n",
    "\n",
    "    # Assuming lyrics data is in data[0, 3]\n",
    "    word_list = data[0, 3]\n",
    "\n",
    "    lyrics = \"\"\n",
    "    for phrase in word_list:\n",
    "        line = \"\"\n",
    "        for part in phrase:\n",
    "            line += \"\".join(part) + \" \"\n",
    "        lyrics += line.strip() + \"\\n\"\n",
    "    return lyrics\n",
    "\n",
    "def create_lyrics_midi_dataframe(npy_folder, midi_folder):\n",
    "    \"\"\"\n",
    "    Creates a Pandas DataFrame with lyrics and corresponding MIDI file paths.\n",
    "\n",
    "    Args:\n",
    "        npy_folder: Path to the folder containing .npy files.\n",
    "        midi_folder: Path to the folder containing the corresponding MIDI files.\n",
    "\n",
    "    Returns:\n",
    "        A Pandas DataFrame with 'lyrics' and 'midi_path' columns.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for filename in os.listdir(npy_folder):\n",
    "        if filename.endswith(\".npy\"):\n",
    "            npy_path = os.path.join(npy_folder, filename)\n",
    "            midi_filename = os.path.splitext(filename)[0] + \".mid\"\n",
    "            midi_path = os.path.join(midi_folder, midi_filename)\n",
    "\n",
    "            # Check if the corresponding MIDI file exists\n",
    "            if os.path.exists(midi_path):\n",
    "                try:\n",
    "                    lyrics = extract_lyrics(npy_path)\n",
    "                    if lyrics.strip():  # Check if lyrics are not empty after removing whitespace\n",
    "                        data.append({'lyrics': lyrics, 'midi_path': midi_path})\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {filename}: {e}\")\n",
    "            else:\n",
    "                print(f\"MIDI file not found for {filename}\")\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage:\n",
    "npy_folder = \"data/lmd-full_and_reddit_MIDI_dataset/sentenceWord_level_6\"\n",
    "midi_folder = \"data/lmd-full_and_reddit_MIDI_dataset/sentenceWord_level_6_MIDI\"\n",
    "\n",
    "df = create_lyrics_midi_dataframe(npy_folder, midi_folder)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6291099-900d-4f79-a9ba-6210c9f5310c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "# For reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f71a6e9-ecc7-4ce4-a14a-5eaea6d48bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from copy import deepcopy\n",
    "from symusic import Note, Score\n",
    "\n",
    "def randomize_midi_pitch(midi_score, prob=0.2, max_change=4):\n",
    "    \"\"\"\n",
    "    Randomizes the pitch of notes in a symusic.Score object with a given probability.\n",
    "\n",
    "    Args:\n",
    "        midi_score: A symusic.Score object.\n",
    "        prob: The probability of applying pitch randomization to a note.\n",
    "        max_change: The maximum number of semitones to add or subtract.\n",
    "\n",
    "    Returns:\n",
    "        A new symusic.Score object with the randomized pitches.\n",
    "    \"\"\"\n",
    "    new_score = deepcopy(midi_score)\n",
    "\n",
    "    for track in new_score.tracks:\n",
    "        for note in track.notes:\n",
    "            if random.random() < prob:\n",
    "                # Generate a random change within the range [-max_change, max_change]\n",
    "                change = random.randint(-max_change, max_change)\n",
    "\n",
    "                # Apply the change to the note's pitch\n",
    "                new_pitch = note.pitch + change\n",
    "\n",
    "                # Ensure the new pitch is within a valid range (0-127 for MIDI)\n",
    "                new_pitch = max(0, min(new_pitch, 127))\n",
    "\n",
    "                # Update the note's pitch\n",
    "                note.pitch = new_pitch\n",
    "\n",
    "    return new_score\n",
    "\n",
    "\n",
    "class LyricsMidiDataset(Dataset):\n",
    "    def __init__(self, dataframe, lyrics_tokenizer, midi_tokenizer, max_length):\n",
    "        self.dataframe = dataframe\n",
    "        self.lyrics_tokenizer = lyrics_tokenizer\n",
    "        self.midi_tokenizer = midi_tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lyrics = self.dataframe.iloc[idx]['lyrics']\n",
    "        midi_path = self.dataframe.iloc[idx]['midi_path']\n",
    "\n",
    "        # Tokenize lyrics\n",
    "        lyrics = lyrics + self.lyrics_tokenizer.eos_token\n",
    "        lyrics_tokens = self.lyrics_tokenizer(lyrics, \n",
    "                                             return_tensors=\"pt\", \n",
    "                                             max_length=self.max_length, \n",
    "                                             padding=\"max_length\", \n",
    "                                             truncation=True)\n",
    "        \n",
    "        midi_score = Score(midi_path)\n",
    "        midi_score = randomize_midi_pitch(midi_score)\n",
    "        \n",
    "        # Tokenize MIDI (using your custom tokenizer)\n",
    "        midi_tokens = self.midi_tokenizer(midi_score)[0].ids\n",
    "        midi_tokens = midi_tokens[:self.max_length] # Truncate\n",
    "        \n",
    "        # Pad MIDI tokens \n",
    "        padding_length = self.max_length - len(midi_tokens)\n",
    "        midi_tokens = midi_tokens + [0] * padding_length # Assuming 0 is your padding token for MIDI\n",
    "        midi_tokens = torch.tensor(midi_tokens, dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            'lyrics_ids': lyrics_tokens['input_ids'].squeeze(),\n",
    "            'lyrics_attention_mask': lyrics_tokens['attention_mask'].squeeze(),\n",
    "            'midi_tokens': midi_tokens\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7df652d0-3fdd-47f6-b31e-faa9ef7e1802",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyricsGenerator(nn.Module):\n",
    "    def __init__(self, lyrics_vocab_size, midi_vocab_size, d_model, max_length):\n",
    "        super(LyricsGenerator, self).__init__()\n",
    "\n",
    "        self.midi_embedding = nn.Embedding(midi_vocab_size, d_model)\n",
    "        self.lyrics_embedding = nn.Embedding(lyrics_vocab_size, d_model)\n",
    "        self.positional_embedding = nn.Embedding(max_length, d_model)\n",
    "\n",
    "        self.linear = nn.Linear(d_model, d_model)  # Linear layer for MIDI\n",
    "        \n",
    "        self.gpt2 = GPT2LMHeadModel.from_pretrained('gpt2', \n",
    "                                                   pad_token_id=lyrics_tokenizer.eos_token_id)\n",
    "\n",
    "        # Resize embeddings to match lyrics vocab size (IMPORTANT)\n",
    "        self.gpt2.resize_token_embeddings(lyrics_vocab_size)\n",
    "\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, lyrics_ids, lyrics_attention_mask, midi_tokens):\n",
    "        # Create positional embeddings\n",
    "        positions = torch.arange(0, lyrics_ids.size(1)).expand(lyrics_ids.size(0), -1).to(device)\n",
    "        positional_embeds = self.positional_embedding(positions)\n",
    "\n",
    "        # MIDI embeddings and linear transformation\n",
    "        midi_embeds = self.midi_embedding(midi_tokens)\n",
    "        midi_embeds = self.linear(midi_embeds)  # Shape: (batch_size, seq_len, d_model)\n",
    "\n",
    "        # Lyrics embeddings\n",
    "        lyrics_embeds = self.lyrics_embedding(lyrics_ids) + positional_embeds\n",
    "\n",
    "        # Concatenate along the sequence length dimension\n",
    "        combined_embeds = torch.cat((midi_embeds, lyrics_embeds), dim=1)\n",
    "        # Adjust attention mask for combined sequence (filled with 1s for simplicity)\n",
    "        combined_attention_mask = torch.ones_like(combined_embeds[..., 0]).to(device)\n",
    "\n",
    "        # Pass through GPT-2\n",
    "        outputs = self.gpt2(inputs_embeds=combined_embeds,\n",
    "                            attention_mask=combined_attention_mask)\n",
    "        \n",
    "        # Return logits for lyrics part, taking into account the offset from the midi sequence length\n",
    "        return outputs.logits[:, midi_embeds.size(1):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aee343d-b844-4712-96fb-097513682275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, scheduler, epochs):\n",
    "    model.train()\n",
    "    loss_fct = nn.CrossEntropyLoss(ignore_index=lyrics_tokenizer.pad_token_id)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        loop = tqdm(dataloader, leave=True)\n",
    "        for batch in loop:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            lyrics_ids = batch['lyrics_ids'].to(device)\n",
    "            lyrics_attention_mask = batch['lyrics_attention_mask'].to(device)\n",
    "            midi_tokens = batch['midi_tokens'].to(device)\n",
    "\n",
    "            outputs = model(lyrics_ids=lyrics_ids,\n",
    "                            lyrics_attention_mask=lyrics_attention_mask,\n",
    "                            midi_tokens=midi_tokens)\n",
    "\n",
    "            loss = loss_fct(outputs.transpose(1, 2), lyrics_ids)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # --- Prediction and Printing ---\n",
    "            # Get predictions (argmax over the vocabulary dimension)\n",
    "            #predictions = torch.argmax(outputs, dim=-1)\n",
    "\n",
    "            # Decode predictions and ground truth\n",
    "            #predicted_lyrics = [lyrics_tokenizer.decode(pred, skip_special_tokens=False) for pred in predictions]\n",
    "            #ground_truth_lyrics = [lyrics_tokenizer.decode(label, skip_special_tokens=False) for label in lyrics_ids]\n",
    "\n",
    "            # Print for each item in the batch\n",
    "            #for i in range(len(predicted_lyrics)):\n",
    "            #    print(f\"  Predicted: {predicted_lyrics[i]}\")\n",
    "            #    print(f\"  Ground Truth: {ground_truth_lyrics[i]}\")\n",
    "            # ---------------------------------\n",
    "\n",
    "            loop.set_description(f\"Epoch {epoch}\")\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Create a checkpoint dictionary\n",
    "    checkpoint = {\n",
    "        'epoch': epochs,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),  # If you want to save the scheduler's state\n",
    "        'loss': loss,  # Or any other metric you want to save (e.g., validation BLEU)\n",
    "    }\n",
    "\n",
    "    # Save the checkpoint\n",
    "    torch.save(checkpoint, 'model_checkpoint.pth')  # Or any filename you prefer\n",
    "    print(\"Checkpoint saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5085a412-88e3-4073-9f5c-247253d8fece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lyrics(model, midi_path, lyrics_tokenizer, midi_tokenizer, max_length, num_beams=5):\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize MIDI\n",
    "    midi_tokens = midi_tokenizer(midi_path)[0].ids\n",
    "    midi_tokens = midi_tokens[:max_length]\n",
    "    padding_length = max_length - len(midi_tokens)\n",
    "    midi_tokens = midi_tokens + [0] * padding_length\n",
    "    midi_tokens = torch.tensor(midi_tokens, dtype=torch.long).unsqueeze(0).to(device) # Add batch dimension\n",
    "\n",
    "    # Prepare initial input for GPT-2 (use a special start token, e.g., <|startoftext|>)\n",
    "    input_ids = torch.tensor(lyrics_tokenizer.encode(\"<|endoftext|>\")).unsqueeze(0).to(device)\n",
    "    attention_mask = torch.ones_like(input_ids).to(device)\n",
    "    \n",
    "    # Generate with beam search\n",
    "    beam_output = model.gpt2.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=max_length,\n",
    "        num_beams=num_beams,\n",
    "        early_stopping=False,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=lyrics_tokenizer.pad_token_id,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "    # Decode the generated lyrics\n",
    "    generated_lyrics = lyrics_tokenizer.decode(beam_output[0], skip_special_tokens=True)\n",
    "\n",
    "    return generated_lyrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c9575b6-f41a-43de-a624-909165c8e656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "/opt/conda/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "from pathlib import Path\n",
    "from miditok import TSD, TokenizerConfig\n",
    "\n",
    "# Load MIDI Tokenizer\n",
    "config = TokenizerConfig(\n",
    "    num_velocities=1,  # Remove velocity tokens (not relevant for your vocal data)\n",
    "    use_chords=False,  # Disable chord tokens (unless your vocals have complex harmonies)\n",
    "    use_rests=False,  # Disable rest tokens (unless silence is significant in your data)\n",
    "    use_tempos=False,  # Disable tempo tokens (unless you have multiple pieces with varying tempos)\n",
    "    use_time_signatures=False,  # Disable time signature tokens (unless relevant to your data)\n",
    ")\n",
    "\n",
    "midi_tokenizer = TSD(config)\n",
    "\n",
    "midi_tokenizer = midi_tokenizer.from_pretrained(Path(\"tokenizer\", \"tokenizer.json\"))\n",
    "\n",
    "# Hyperparameters\n",
    "max_length = 512\n",
    "batch_size = 4\n",
    "epochs = 6\n",
    "d_model = 768 # GPT-2's dimension\n",
    "midi_vocab_size = len(midi_tokenizer)\n",
    "lyrics_vocab_size = None # Placeholder, will be set after initializing the tokenizer\n",
    "\n",
    "# Load GPT-2 tokenizer\n",
    "lyrics_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "lyrics_tokenizer.add_special_tokens({'pad_token': '<|pad|>'})\n",
    "lyrics_vocab_size = len(lyrics_tokenizer)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = LyricsMidiDataset(df, lyrics_tokenizer, midi_tokenizer, max_length)\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Instantiate model\n",
    "model = LyricsGenerator(lyrics_vocab_size, midi_vocab_size, d_model, max_length).to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911d6dc8-af93-478c-b5bd-95f36b34c355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train(model, train_dataloader, optimizer, scheduler, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46f6daa1-f6b5-4df2-a1f0-0f3c75b49f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Lyrics:\n",
      "We know that we can make money out of these kinds of things, but we can't really know what is going on in the world's mind. And we can only make money out of these kinds of things. And we can only make money out of these kinds of things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things.\n",
      "\n",
      "But we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things.\n",
      "\n",
      "But we can only make money out of these things. and we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things. And we can only make money out of these things.\n",
      "\n",
      "But we can only make money out of these things. and we can only make money out of these things. And we can only make money out of these things.\n",
      "\n",
      "Chad showch chad showch chad showch, and we can only make money out of these things.\n",
      "\n",
      "Chad show\n",
      "Original Lyrics:\n",
      "Mary was married with Had the\n",
      "suburban life\n",
      "till her husband came clean\n",
      "with the help of Jim Beam\n",
      "and confessed his sins one night\n",
      "Said fallen in love with a said\n",
      "she made him feel reckless and And when he\n",
      "was through\n",
      "what else could she\n",
      "She just let that pony run\n",
      "you do\n",
      "what you when you know\n",
      "you You hang on\n",
      "you then you learn to let go\n",
      "And you get what you need sometimes\n",
      "but when said and done\n",
      "you do\n",
      "you then you let that pony run\n",
      "Now Mary moved to West\n",
      "after the shock wore off\n",
      "She got a divorce\n",
      "and a chestnut horse\n",
      "and a barn with an old hayloft\n",
      "And sometimes she rides down by the river\n",
      "Said it makes her feel reckless and young\n",
      "She just closes her eyes\n",
      "and she holds on tight\n",
      "and she lets that pony run\n",
      "you do\n",
      "what you when you know\n",
      "you You hang on\n",
      "you then you learn to let go\n",
      "And you get what you need sometimes\n",
      "but when said and done\n",
      "you do\n",
      "you then you let that pony run\n",
      "let that pony run\n",
      "Oh no oh no babe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example inference (replace with a real MIDI path)\n",
    "midi_path = df[\"midi_path\"][7]\n",
    "generated_lyrics = generate_lyrics(model, midi_path, lyrics_tokenizer, midi_tokenizer, max_length)\n",
    "print(f\"Generated Lyrics:\\n{generated_lyrics}\")\n",
    "print(f\"Original Lyrics:\\n{df[\"lyrics\"][7]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36e5f72-63d7-47f0-8c69-4ec6366ffe9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
