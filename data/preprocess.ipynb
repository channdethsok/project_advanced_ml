{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0a86713-2a0c-42cb-bf90-cc9c003618ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Unzip the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c174310f-64ba-4d6e-9638-9209064752dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully unzipped 'lmd-full_and_reddit_MIDI_dataset/sentenceWord_level_6.zip' to 'lmd-full_and_reddit_MIDI_dataset/'\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "def unzip_file(zip_file_path, extract_to_path):\n",
    "  \"\"\"\n",
    "  Unzips a zip file to a specified directory.\n",
    "\n",
    "  Args:\n",
    "      zip_file_path: The path to the zip file.\n",
    "      extract_to_path: The path to the directory where contents should be extracted.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "      zip_ref.extractall(extract_to_path)\n",
    "    print(f\"Successfully unzipped '{zip_file_path}' to '{extract_to_path}'\")\n",
    "  except FileNotFoundError:\n",
    "    print(f\"Error: Zip file not found at '{zip_file_path}'\")\n",
    "  except zipfile.BadZipFile:\n",
    "    print(f\"Error: Invalid zip file: '{zip_file_path}'\")\n",
    "  except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage (replace with your file paths):\n",
    "zip_file_path = 'lmd-full_and_reddit_MIDI_dataset/sentenceWord_level_6.zip'  # Path to the zip file you want to unzip\n",
    "extract_to_path = 'lmd-full_and_reddit_MIDI_dataset/'  # Path to the directory to extract to\n",
    "\n",
    "# Create the extraction directory if it doesn't exist\n",
    "if not os.path.exists(extract_to_path):\n",
    "    os.makedirs(extract_to_path)\n",
    "\n",
    "unzip_file(zip_file_path, extract_to_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd87281-c654-4d51-8d20-7816841a8c5d",
   "metadata": {},
   "source": [
    "# Explore a npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9065815c-165c-44b7-aee3-a9c170962fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: lmd-full_and_reddit_MIDI_dataset/sentenceWord_level_6/TURNER.When the heartache is over K.npy\n",
      "Data type: object\n",
      "Shape: (1, 4)\n",
      "The array contains objects.\n",
      "  Item at index (0, 0):\n",
      "    Object Type: <class 'list'>\n",
      "    Value: [[[[0.0, 0.25441833333333363, 146.8323839587038, 125.0]]], [[[0.2654799999999966, 0.25441833333333363, 174.61411571650194, 125.0]], [[0.2654800000000037, 0.25441833333333363, 329.6275569128699, 125.0]], [[0.2654799999999966, 0.25441833333333363, 329.6275569128699, 125.0]], [[0.2654800000000037, 0.25441833333332653, 164.81377845643496, 125.0]]], [[[0.5309600000000003, 0.25441833333333363, 329.6275569128699, 125.0]]], [[[0.2654799999999966, 0.25441833333333363, 293.6647679174076, 125.0]], [[0.796440000000004, 0.2544183333333194, 146.8323839587038, 125.0]], [[0.2654799999999966, 0.25441833333333363, 164.81377845643496, 125.0]]], [[[0.2654799999999966, 0.25441833333333363, 174.61411571650194, 125.0]], [[0.2654799999999966, 0.25441833333333363, 293.6647679174076, 125.0]], [[0.5309600000000074, 0.25441833333333363, 164.81377845643496, 125.0]], [[0.2654800000000108, 0.25441833333333363, 329.6275569128699, 125.0]], [[0.2654799999999966, 0.25441833333333363, 349.2282314330039, 125.0]]], [], [[[0.2654800000000108, 0.25441833333333363, 349.2282314330039, 125.0]], [[0.5309599999999932, 0.25441833333333363, 329.6275569128699, 125.0]]], [], [[[0.2654799999999966, 0.25441833333333363, 164.81377845643496, 125.0]], [[0.2654799999999966, 0.25441833333333363, 146.8323839587038, 125.0]]], [], [[[0.2654800000000108, 0.2544183333333194, 293.6647679174076, 125.0]]], [[[0.5309600000000074, 0.25441833333333363, 329.6275569128699, 125.0]], [[0.7964399999999898, 0.25441833333334785, 293.6647679174076, 125.0]]], [[[0.2654799999999966, 0.25441833333334785, 329.6275569128699, 125.0]]]]\n",
      "  Item at index (0, 1):\n",
      "    Object Type: <class 'list'>\n",
      "    Value: [[[[50.0, 0.5, 0.0]]], [[[53.0, 0.5, 0.0]], [[64.0, 0.5, 0.0]], [[64.0, 0.5, 0.0]], [[52.0, 0.5, 0.0]]], [[[64.0, 0.5, 1.0]]], [[[62.0, 0.5, 0.0]], [[50.0, 0.5, 0.0]], [[52.0, 0.5, 0.0]]], [[[53.0, 0.5, 0.0]], [[62.0, 0.5, 0.0]], [[52.0, 0.5, 0.0]], [[64.0, 0.5, 0.0]], [[65.0, 0.5, 0.0]]], [], [[[65.0, 0.5, 0.0]], [[64.0, 0.5, 1.0]]], [], [[[52.0, 0.5, 0.0]], [[50.0, 0.5, 0.0]]], [], [[[62.0, 0.5, 0.0]]], [[[64.0, 0.5, 1.0]], [[62.0, 0.5, 0.0]]], [[[64.0, 0.5, 0.0]]]]\n",
      "  Item at index (0, 2):\n",
      "    Object Type: <class 'list'>\n",
      "    Value: [[['Who']], [['you'], ['you'], ['you'], ['the']], [['is']], [['I'], ['I'], ['I']], [['be'], ['I'], ['Oh'], ['I'], ['can']], [], [['on'], ['with']], [], [['know'], ['you']], [], [['that']], [['you'], ['you']], [['look']]]\n",
      "  Item at index (0, 3):\n",
      "    Object Type: <class 'list'>\n",
      "    Value: [[['Who']], [['you'], ['you'], ['you'], ['the']], [['is']], [['I'], ['I'], ['I']], [['be'], ['I'], ['Oh'], ['I'], ['can']], [], [['on'], ['with']], [], [['know'], ['you']], [], [['that']], [['you'], ['you']], [['look']]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def inspect_npy_file(file_path):\n",
    "    \"\"\"\n",
    "    Loads and inspects the contents of a .npy file.\n",
    "\n",
    "    Args:\n",
    "        file_path: The path to the .npy file.\n",
    "\n",
    "    Returns:\n",
    "        None. Prints information about the array stored in the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the .npy file\n",
    "        data = np.load(file_path, allow_pickle=True)\n",
    "\n",
    "        # Print information about the array\n",
    "        print(f\"File: {file_path}\")\n",
    "        print(f\"Data type: {data.dtype}\")\n",
    "        print(f\"Shape: {data.shape}\")\n",
    "\n",
    "        if data.dtype == 'object':\n",
    "            print(\"The array contains objects.\")\n",
    "            if data.ndim == 0:\n",
    "                # Handle 0-dimensional object arrays (scalar objects)\n",
    "                print(f\"  Object Type: {type(data.item())}\")\n",
    "                if isinstance(data.item(), dict):\n",
    "                    print(\"  Keys:\", data.item().keys())\n",
    "                else:\n",
    "                    print(f\"  Value: {data.item()}\")\n",
    "            else:\n",
    "                # Handle multi-dimensional object arrays\n",
    "                for i in range(data.shape[0]):\n",
    "                    for j in range(data.shape[1]):\n",
    "                        item = data[i, j]\n",
    "                        print(f\"  Item at index ({i}, {j}):\")\n",
    "                        print(f\"    Object Type: {type(item)}\")\n",
    "                        if isinstance(item, dict):\n",
    "                            print(\"    Keys:\", item.keys())\n",
    "                        else:\n",
    "                            print(f\"    Value: {item}\")\n",
    "\n",
    "        else:\n",
    "            # Handle numerical arrays\n",
    "            print(\"First few elements (up to 10):\")\n",
    "            if data.ndim == 1:\n",
    "                print(data[:10])\n",
    "            elif data.ndim == 2:\n",
    "                print(data[:min(data.shape[0], 10), :min(data.shape[1], 10)])\n",
    "            else:\n",
    "                print(data.flatten()[:10])\n",
    "\n",
    "            # If it's a small array, print the entire array\n",
    "            if data.size < 20:\n",
    "                print(\"Full array:\")\n",
    "                print(data)\n",
    "\n",
    "        # Handle metadata (if present)\n",
    "        if hasattr(data, 'metadata') and data.metadata is not None:\n",
    "            print(\"\\nMetadata:\")\n",
    "            for key, value in data.metadata.items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "file_path = \"lmd-full_and_reddit_MIDI_dataset/sentenceWord_level_6/TURNER.When the heartache is over K.npy\"\n",
    "\n",
    "\n",
    "inspect_npy_file(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc1acd5-e8e8-4a89-987a-9d50b722fbea",
   "metadata": {},
   "source": [
    "# Make midi files out of the npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0765e8-314d-4cb5-98b9-25467438572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pretty_midi\n",
    "import os\n",
    "\n",
    "def npy_to_midi_discrete(npy_file, midi_file, tempo=120):\n",
    "    \"\"\"\n",
    "    Converts a .npy file with encoded musical data (discrete attributes only)\n",
    "    into a MIDI file.\n",
    "\n",
    "    Args:\n",
    "        npy_file: Path to the input .npy file.\n",
    "        midi_file: Path to the output MIDI file (.mid).\n",
    "        tempo: Tempo of the MIDI file in beats per minute (BPM).\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the .npy file\n",
    "    data = np.load(npy_file, allow_pickle=True)\n",
    "\n",
    "    # Create a PrettyMIDI object\n",
    "    midi = pretty_midi.PrettyMIDI(initial_tempo=tempo)\n",
    "\n",
    "    # Create an instrument instance for a piano (instrument number 0)\n",
    "    instrument = pretty_midi.Instrument(program=0)\n",
    "\n",
    "    # Assuming data[0, 1] is discrete\n",
    "    discrete_data = data[0, 1]\n",
    "\n",
    "    # Keep track of the current time in the MIDI file\n",
    "    current_time = 0\n",
    "\n",
    "    for sentence_index, sentence in enumerate(discrete_data):\n",
    "        for word_index, word in enumerate(sentence):\n",
    "            for note_index, note in enumerate(word):\n",
    "                pitch = int(note[0])\n",
    "                duration_staves = note[1]\n",
    "                rest_duration_staves = note[2]\n",
    "\n",
    "                # Calculate note duration in seconds based on tempo and staves\n",
    "                note_duration_seconds = (60 / tempo) * duration_staves\n",
    "\n",
    "                # Calculate rest duration in seconds\n",
    "                rest_duration_seconds = (60 / tempo) * rest_duration_staves\n",
    "\n",
    "                # Advance current time by the rest duration\n",
    "                current_time += rest_duration_seconds\n",
    "\n",
    "                # Create a PrettyMIDI Note instance\n",
    "                pm_note = pretty_midi.Note(\n",
    "                    velocity=100,  # Default velocity\n",
    "                    pitch=pitch,\n",
    "                    start=current_time,\n",
    "                    end=current_time + note_duration_seconds\n",
    "                )\n",
    "\n",
    "                # Add the note to the instrument\n",
    "                instrument.notes.append(pm_note)\n",
    "\n",
    "                # Advance current time by the note duration\n",
    "                current_time += note_duration_seconds\n",
    "\n",
    "    # Add the instrument to the MIDI object\n",
    "    midi.instruments.append(instrument)\n",
    "\n",
    "    # Write the MIDI data to a file\n",
    "    midi.write(midi_file)\n",
    "    print(f\"MIDI file saved to: {midi_file}\")\n",
    "\n",
    "def convert_folder_to_midi(npy_folder, midi_folder, tempo=120):\n",
    "    \"\"\"\n",
    "    Converts all .npy files in a folder to MIDI files using discrete data.\n",
    "\n",
    "    Args:\n",
    "        npy_folder: Path to the folder containing .npy files.\n",
    "        midi_folder: Path to the folder where MIDI files will be saved.\n",
    "        tempo: Tempo for the MIDI files in BPM.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the MIDI output folder if it doesn't exist\n",
    "    if not os.path.exists(midi_folder):\n",
    "        os.makedirs(midi_folder)\n",
    "\n",
    "    # Iterate through all files in the .npy folder\n",
    "    for filename in os.listdir(npy_folder):\n",
    "        if filename.endswith(\".npy\"):\n",
    "            npy_path = os.path.join(npy_folder, filename)\n",
    "            midi_filename = os.path.splitext(filename)[0] + \".mid\"\n",
    "            midi_path = os.path.join(midi_folder, midi_filename)\n",
    "\n",
    "            try:\n",
    "                npy_to_midi_discrete(npy_path, midi_path, tempo=tempo)\n",
    "            except Exception as e:\n",
    "                print(f\"Error converting {filename}: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "npy_folder = \"lmd-full_and_reddit_MIDI_dataset/sentenceWord_level_6\"  # Replace with your .npy folder\n",
    "midi_folder = \"lmd-full_and_reddit_MIDI_dataset/sentenceWord_level_6_MIDI\"  # Replace with your desired output folder\n",
    "tempo = 120  # Set the desired tempo\n",
    "\n",
    "convert_folder_to_midi(npy_folder, midi_folder, tempo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bb7372-418f-418a-ac4c-d5b009370d0d",
   "metadata": {},
   "source": [
    "# Make a pandas dataframe containing the lyrics and the path to the midi files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ff952d2-9b51-4b6b-b91c-9988980801db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>midi_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In sleep he sang to me\\nin dreams he came\\ntha...</td>\n",
       "      <td>lmd-full_and_reddit_MIDI_dataset/sentenceWord_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have plans and schemes\\nAnd I have hopes and...</td>\n",
       "      <td>lmd-full_and_reddit_MIDI_dataset/sentenceWord_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I get up and nothing gets me You got\\nit tough...</td>\n",
       "      <td>lmd-full_and_reddit_MIDI_dataset/sentenceWord_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man a hot like seven inches\\nfrom the midday I...</td>\n",
       "      <td>lmd-full_and_reddit_MIDI_dataset/sentenceWord_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We come from the land of the ice and snow\\nfro...</td>\n",
       "      <td>lmd-full_and_reddit_MIDI_dataset/sentenceWord_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics  \\\n",
       "0  In sleep he sang to me\\nin dreams he came\\ntha...   \n",
       "1  I have plans and schemes\\nAnd I have hopes and...   \n",
       "2  I get up and nothing gets me You got\\nit tough...   \n",
       "3  Man a hot like seven inches\\nfrom the midday I...   \n",
       "4  We come from the land of the ice and snow\\nfro...   \n",
       "\n",
       "                                           midi_path  \n",
       "0  lmd-full_and_reddit_MIDI_dataset/sentenceWord_...  \n",
       "1  lmd-full_and_reddit_MIDI_dataset/sentenceWord_...  \n",
       "2  lmd-full_and_reddit_MIDI_dataset/sentenceWord_...  \n",
       "3  lmd-full_and_reddit_MIDI_dataset/sentenceWord_...  \n",
       "4  lmd-full_and_reddit_MIDI_dataset/sentenceWord_...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def extract_lyrics(npy_file):\n",
    "    \"\"\"\n",
    "    Extracts lyrics from a .npy file.\n",
    "\n",
    "    Args:\n",
    "        npy_file: Path to the input .npy file.\n",
    "\n",
    "    Returns:\n",
    "        A string containing the extracted lyrics.\n",
    "    \"\"\"\n",
    "    data = np.load(npy_file, allow_pickle=True)\n",
    "\n",
    "    # Assuming lyrics data is in data[0, 3]\n",
    "    word_list = data[0, 3]\n",
    "\n",
    "    lyrics = \"\"\n",
    "    for phrase in word_list:\n",
    "        line = \"\"\n",
    "        for part in phrase:\n",
    "            line += \"\".join(part) + \" \"\n",
    "        lyrics += line.strip() + \"\\n\"\n",
    "    return lyrics\n",
    "\n",
    "def create_lyrics_midi_dataframe(npy_folder, midi_folder):\n",
    "    \"\"\"\n",
    "    Creates a Pandas DataFrame with lyrics and corresponding MIDI file paths.\n",
    "\n",
    "    Args:\n",
    "        npy_folder: Path to the folder containing .npy files.\n",
    "        midi_folder: Path to the folder containing the corresponding MIDI files.\n",
    "\n",
    "    Returns:\n",
    "        A Pandas DataFrame with 'lyrics' and 'midi_path' columns.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for filename in os.listdir(npy_folder):\n",
    "        if filename.endswith(\".npy\"):\n",
    "            npy_path = os.path.join(npy_folder, filename)\n",
    "            midi_filename = os.path.splitext(filename)[0] + \".mid\"\n",
    "            midi_path = os.path.join(midi_folder, midi_filename)\n",
    "\n",
    "            # Check if the corresponding MIDI file exists\n",
    "            if os.path.exists(midi_path):\n",
    "                try:\n",
    "                    lyrics = extract_lyrics(npy_path)\n",
    "                    if lyrics.strip():  # Check if lyrics are not empty after removing whitespace\n",
    "                        data.append({'lyrics': lyrics, 'midi_path': midi_path})\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {filename}: {e}\")\n",
    "            else:\n",
    "                print(f\"MIDI file not found for {filename}\")\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage:\n",
    "npy_folder = \"lmd-full_and_reddit_MIDI_dataset/sentenceWord_level_6\"  # Replace with your .npy folder\n",
    "midi_folder = \"lmd-full_and_reddit_MIDI_dataset/sentenceWord_level_6_MIDI\"  # Replace with your MIDI folder\n",
    "\n",
    "df = create_lyrics_midi_dataframe(npy_folder, midi_folder)\n",
    "df.head()\n",
    "\n",
    "# Save to CSV (optional)\n",
    "# df.to_csv(\"lyrics_midi_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccba224-e9b2-4105-b739-cb98cb126f24",
   "metadata": {},
   "source": [
    "# Tokenize the midi files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b64663a7-987a-401f-9d8d-208cf4e75be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokSequence(tokens=['Pitch_46', 'Velocity_127', 'Duration_1.0.8', 'TimeShift_1.0.8', 'Pitch_50', 'Velocity_127', 'Duration_1.0.8', 'TimeShift_2.0.8', 'Pitch_53', 'Velocity_127'], ids=[29, 92, 100, 164, 33, 92, 100, 172, 36, 92], bytes='', events=[Event(type=Pitch, value=46, time=0, desc=8), Event(type=Velocity, value=127, time=0, desc=127), Event(type=Duration, value=1.0.8, time=0, desc=8 ticks), Event(type=TimeShift, value=1.0.8, time=0, desc=8 ticks), Event(type=Pitch, value=50, time=8, desc=16), Event(type=Velocity, value=127, time=8, desc=127), Event(type=Duration, value=1.0.8, time=8, desc=8 ticks), Event(type=TimeShift, value=2.0.8, time=8, desc=16 ticks), Event(type=Pitch, value=53, time=24, desc=32), Event(type=Velocity, value=127, time=24, desc=127)], are_ids_encoded=False, _ticks_bars=[0, 32, 64, 96, 128, 160, 192, 224, 256, 288, 320, 352, 384, 416, 448, 480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800, 832, 864, 896, 928, 960, 992, 1024, 1056, 1088, 1120, 1152, 1184, 1216, 1248, 1280, 1312, 1344, 1376, 1408, 1440, 1472, 1504, 1536, 1568, 1600, 1632, 1664, 1696, 1728, 1760, 1792, 1824, 1856, 1888, 1920, 1952, 1984, 2016, 2048, 2080, 2112, 2144, 2176, 2208, 2240, 2272, 2304, 2336, 2368, 2400, 2432, 2464, 2496, 2528, 2560, 2592], _ticks_beats=[0, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400, 408, 416, 424, 432, 440, 448, 456, 464, 472, 480, 488, 496, 504, 512, 520, 528, 536, 544, 552, 560, 568, 576, 584, 592, 600, 608, 616, 624, 632, 640, 648, 656, 664, 672, 680, 688, 696, 704, 712, 720, 728, 736, 744, 752, 760, 768, 776, 784, 792, 800, 808, 816, 824, 832, 840, 848, 856, 864, 872, 880, 888, 896, 904, 912, 920, 928, 936, 944, 952, 960, 968, 976, 984, 992, 1000, 1008, 1016, 1024, 1032, 1040, 1048, 1056, 1064, 1072, 1080, 1088, 1096, 1104, 1112, 1120, 1128, 1136, 1144, 1152, 1160, 1168, 1176, 1184, 1192, 1200, 1208, 1216, 1224, 1232, 1240, 1248, 1256, 1264, 1272, 1280, 1288, 1296, 1304, 1312, 1320, 1328, 1336, 1344, 1352, 1360, 1368, 1376, 1384, 1392, 1400, 1408, 1416, 1424, 1432, 1440, 1448, 1456, 1464, 1472, 1480, 1488, 1496, 1504, 1512, 1520, 1528, 1536, 1544, 1552, 1560, 1568, 1576, 1584, 1592, 1600, 1608, 1616, 1624, 1632, 1640, 1648, 1656, 1664, 1672, 1680, 1688, 1696, 1704, 1712, 1720, 1728, 1736, 1744, 1752, 1760, 1768, 1776, 1784, 1792, 1800, 1808, 1816, 1824, 1832, 1840, 1848, 1856, 1864, 1872, 1880, 1888, 1896, 1904, 1912, 1920, 1928, 1936, 1944, 1952, 1960, 1968, 1976, 1984, 1992, 2000, 2008, 2016, 2024, 2032, 2040, 2048, 2056, 2064, 2072, 2080, 2088, 2096, 2104, 2112, 2120, 2128, 2136, 2144, 2152, 2160, 2168, 2176, 2184, 2192, 2200, 2208, 2216, 2224, 2232, 2240, 2248, 2256, 2264, 2272, 2280, 2288, 2296, 2304, 2312, 2320, 2328, 2336, 2344, 2352, 2360, 2368, 2376, 2384, 2392, 2400, 2408, 2416, 2424, 2432, 2440, 2448, 2456, 2464, 2472, 2480, 2488, 2496, 2504, 2512, 2520, 2528, 2536, 2544, 2552, 2560, 2568, 2576, 2584, 2592, 2600, 2608, 2616], _ids_decoded=[])\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from miditok import TSD, TokenizerConfig\n",
    "\n",
    "# Define the configuration\n",
    "config = TokenizerConfig(\n",
    "    num_velocities=1,  # Remove velocity tokens (not relevant for your vocal data)\n",
    "    use_chords=False,  # Disable chord tokens (unless your vocals have complex harmonies)\n",
    "    use_rests=False,  # Disable rest tokens (unless silence is significant in your data)\n",
    "    use_tempos=False,  # Disable tempo tokens (unless you have multiple pieces with varying tempos)\n",
    "    use_time_signatures=False,  # Disable time signature tokens (unless relevant to your data)\n",
    ")\n",
    "\n",
    "# Create the tokenizer\n",
    "tokenizer = TSD(config)\n",
    "\n",
    "# Tokenize the MIDI files\n",
    "tokens = tokenizer(Path(\"lmd-full_and_reddit_MIDI_dataset/sentenceWord_level_6_MIDI/0a1c541bc1005aea8440ad9f68511bd8.mid\"))\n",
    "print(tokens[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5470cdd1-a001-40d7-a22e-9a18510e9794",
   "metadata": {},
   "source": [
    "## Train tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc86c841-bdaa-4a33-a302-cf3996ca0319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "midi_paths = list(Path(\"lmd-full_and_reddit_MIDI_dataset\", \"sentenceWord_level_6_MIDI\").glob(\"**/*.mid\"))\n",
    "\n",
    "# Train the tokenizer (builds vocabulary)\n",
    "tokenizer.train(vocab_size=30000, files_paths=midi_paths)\n",
    "\n",
    "# Save the tokenizer parameters (vocabulary and configuration)\n",
    "tokenizer.save(Path(\"tokenizer\", \"tokenizer.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77c13fa-a28a-40ed-88f6-9fd8c158b173",
   "metadata": {},
   "source": [
    "## Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2deb5c5e-8d8d-41a3-9fa6-feaea3806665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokSequence(tokens=['Pitch_46', 'Velocity_127', 'Duration_1.0.8', 'TimeShift_1.0.8', 'Pitch_50', 'Velocity_127', 'Duration_1.0.8', 'TimeShift_2.0.8', 'Pitch_53', 'Velocity_127'], ids=[495, 432, 3866, 152, 3019, 2242, 526, 26003, 15440, 10940], bytes='>}\\x85ÅB}\\x85ÍE}', events=[Event(type=Pitch, value=46, time=0, desc=8), Event(type=Velocity, value=127, time=0, desc=127), Event(type=Duration, value=1.0.8, time=0, desc=8 ticks), Event(type=TimeShift, value=1.0.8, time=0, desc=8 ticks), Event(type=Pitch, value=50, time=8, desc=16), Event(type=Velocity, value=127, time=8, desc=127), Event(type=Duration, value=1.0.8, time=8, desc=8 ticks), Event(type=TimeShift, value=2.0.8, time=8, desc=16 ticks), Event(type=Pitch, value=53, time=24, desc=32), Event(type=Velocity, value=127, time=24, desc=127)], are_ids_encoded=True, _ticks_bars=[0, 32, 64, 96, 128, 160, 192, 224, 256, 288, 320, 352, 384, 416, 448, 480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800, 832, 864, 896, 928, 960, 992, 1024, 1056, 1088, 1120, 1152, 1184, 1216, 1248, 1280, 1312, 1344, 1376, 1408, 1440, 1472, 1504, 1536, 1568, 1600, 1632, 1664, 1696, 1728, 1760, 1792, 1824, 1856, 1888, 1920, 1952, 1984, 2016, 2048, 2080, 2112, 2144, 2176, 2208, 2240, 2272, 2304, 2336, 2368, 2400, 2432, 2464, 2496, 2528, 2560, 2592], _ticks_beats=[0, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400, 408, 416, 424, 432, 440, 448, 456, 464, 472, 480, 488, 496, 504, 512, 520, 528, 536, 544, 552, 560, 568, 576, 584, 592, 600, 608, 616, 624, 632, 640, 648, 656, 664, 672, 680, 688, 696, 704, 712, 720, 728, 736, 744, 752, 760, 768, 776, 784, 792, 800, 808, 816, 824, 832, 840, 848, 856, 864, 872, 880, 888, 896, 904, 912, 920, 928, 936, 944, 952, 960, 968, 976, 984, 992, 1000, 1008, 1016, 1024, 1032, 1040, 1048, 1056, 1064, 1072, 1080, 1088, 1096, 1104, 1112, 1120, 1128, 1136, 1144, 1152, 1160, 1168, 1176, 1184, 1192, 1200, 1208, 1216, 1224, 1232, 1240, 1248, 1256, 1264, 1272, 1280, 1288, 1296, 1304, 1312, 1320, 1328, 1336, 1344, 1352, 1360, 1368, 1376, 1384, 1392, 1400, 1408, 1416, 1424, 1432, 1440, 1448, 1456, 1464, 1472, 1480, 1488, 1496, 1504, 1512, 1520, 1528, 1536, 1544, 1552, 1560, 1568, 1576, 1584, 1592, 1600, 1608, 1616, 1624, 1632, 1640, 1648, 1656, 1664, 1672, 1680, 1688, 1696, 1704, 1712, 1720, 1728, 1736, 1744, 1752, 1760, 1768, 1776, 1784, 1792, 1800, 1808, 1816, 1824, 1832, 1840, 1848, 1856, 1864, 1872, 1880, 1888, 1896, 1904, 1912, 1920, 1928, 1936, 1944, 1952, 1960, 1968, 1976, 1984, 1992, 2000, 2008, 2016, 2024, 2032, 2040, 2048, 2056, 2064, 2072, 2080, 2088, 2096, 2104, 2112, 2120, 2128, 2136, 2144, 2152, 2160, 2168, 2176, 2184, 2192, 2200, 2208, 2216, 2224, 2232, 2240, 2248, 2256, 2264, 2272, 2280, 2288, 2296, 2304, 2312, 2320, 2328, 2336, 2344, 2352, 2360, 2368, 2376, 2384, 2392, 2400, 2408, 2416, 2424, 2432, 2440, 2448, 2456, 2464, 2472, 2480, 2488, 2496, 2504, 2512, 2520, 2528, 2536, 2544, 2552, 2560, 2568, 2576, 2584, 2592, 2600, 2608, 2616], _ids_decoded=[])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tokenizer.from_pretrained(Path(\"tokenizer\", \"tokenizer.json\"))\n",
    "tokens = tokenizer(Path(\"lmd-full_and_reddit_MIDI_dataset/sentenceWord_level_6_MIDI/0a1c541bc1005aea8440ad9f68511bd8.mid\"))\n",
    "print(tokens[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e96200c-546e-42e3-9076-9ebf4f057b08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
